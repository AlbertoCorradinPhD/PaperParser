# PaperParser
Corradin A., F. Ciccarese F., V. Raimondi V., L. Urso L., Ciminale V., Silic-Benussi M.. PaperParser: a bioinformatic tool that synthesizes scientific literature through advanced AI techniques, enhancing scholarly insights while mimicking human-like expression.  Proceedings of the 11th World Congress on New Technologies (NewTech'25). Paris, France, August, 2025. DOI: 10.11159/icbb25.161 

# Abstract
In this output-obsessed era, as scientific publishing continues its exponential growth, we've unthinkingly created a paradox: the cumulative advancement of knowledge by humanity now threatens to drive us all into information overload. Into the breach steps, PaperParser, a bioinformatic conductor crafted to gap this mental chasm. At a high level, PaperParser leverages Scrapy's raw extraction strength to crawl PubMed articles, combines this rich knowledge stream with the abstractive summarization ability of the SciLitLLM-14B. It’s in the tool’s layered construction, however—combining RAG methodologies, an autonomous Read-Eval-Print Loop (REPL) agent and Large Language Models—that the system’s complexity truly emerges. By following users’ queries fluently, PaperParser keeps dynamically grouping cohorts of relevant articles that come out from the huge number of articles of the PubMed repository. But the path from data to insight is anything but a straight one: initial corpora is refined through FAISS indexing for fast, relevance-weighted passage retrieval. Drafts are shaped with GPT-40, powered by RAG retrievers that lash generative capability to the evidentiary backbone of a bespoke vector emporium. Further growth of these drafts requires nothing more than an agile AI agent given the reins of GPT-4.1 inside of a Python REPL skeleton. This agile editorial loop yields semantic accuracy as well as emergent clarity. And then, the ‘humanization’ phase. Here, OpenAI’s o3-mini-2025-01-31 is deftly tuned using a Prompt Engineering interface by invoking stylistic signal harvested from target author exemplars through LangChain. PaperParser does not speak as a pure automaton, but as an intermediary, reconciling machine processing speed with a thoughtful, human-touched expression. It allows academics to go beyond mindless reading, shifting their focus to innovative interpretation and critique. We hope to extend this to paywalled periodicals and to perform source relevance-weighting—a further step towards a more discerning and context-sensitive literature navigator. In conclusion: PaperParser represents a new form of scientific intelligence enhancement.

# Use
From Linux shell:
1) create new Python virtual environment
2) install Scrapy
3) test your Internet connection to PubMed database. For example by launching the following command:  'scrapy shell https://pubmed.ncbi.nlm.nih.gov/37076707/'
4) install needed Python modules, included pandas, bs4, sumy, fpdf, torch, transformers, rpy2
5) change direrctory to set the 'working dir' in correspondence of PaperParser, e.g. cd /home/.../paperParser/scraping_rev9
6) launch the Spider with the following command: 
scrapy crawl rev9 -a term=terms-of-search -s CLOSESPIDER_ITEMCOUNT=100, where terms-of-search represents the set of terms a user would insert in PubMed for a usual search in this database.

Then copy everything onto a cloud service like Google Drive for further data elaboration. Open file paperParserLLMs.ipynb with Google Colab and follow the commands reported in its cells.  
