{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CISY3o1KZOrU"
      },
      "source": [
        "#**PAPERPARSER APPLICATION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxqLWaXA_vMo"
      },
      "source": [
        "Mount Google Drive and set the paperParser folder as working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnYjM6nuVVPq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "#!ls\n",
        "import os\n",
        "os.chdir( os.path.join(os.getcwd(),'gdrive/MyDrive' ))\n",
        "#!ls\n",
        "paperParserDir = os.path.join(os.getcwd(),\"paperParserProgram\")\n",
        "print('paperParser directory:')\n",
        "print(paperParserDir )\n",
        "os.chdir(paperParserDir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZvPTHHvwVeK"
      },
      "source": [
        "***PART 1: PREPARE THE DATA***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-RgJHynwPr_"
      },
      "outputs": [],
      "source": [
        "#indicate revision\n",
        "rev='rev9'\n",
        "paperParserVersion='scraping_'+rev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkEapJW_wThh"
      },
      "outputs": [],
      "source": [
        "scrapyDir = os.path.join(paperParserDir,paperParserVersion)\n",
        "print('scrapy directory:')\n",
        "print(scrapyDir)\n",
        "os.chdir(scrapyDir)\n",
        "!ls\n",
        "SciLitDir = os.path.join(scrapyDir, \"SciLit\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "os.chdir(scrapyDir)\n",
        "source_dir = os.path.join(scrapyDir,'abstracts')\n",
        "destination_dir = SciLitDir\n",
        "shutil.copytree(source_dir, destination_dir)"
      ],
      "metadata": {
        "id": "2PNAJbFafFHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IQKcveoG7Fj"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "folder_path='mainTexts'\n",
        "txt_files = glob.glob(folder_path + \"/*.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCWxQnPU7Aj5"
      },
      "source": [
        "Grant access to HuggingFace repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvqx5-xCf9c4"
      },
      "outputs": [],
      "source": [
        "import google.colab\n",
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tul6wgiGIFFm"
      },
      "outputs": [],
      "source": [
        "LLMsDir = os.path.join(scrapyDir,'LLMs')\n",
        "print('LLMs directory:')\n",
        "print(LLMsDir)\n",
        "os.chdir(LLMsDir)\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf==1.7.2\n",
        "!python printFiles.py\n",
        "from printFiles import (printPDF, printTXT)\n",
        "!python getTexts.py\n",
        "from getTexts import (read_content, get_mod_time, merge_per_folder, test_getTexts, mergeSummaries)"
      ],
      "metadata": {
        "id": "_p913h0AsrBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HM9y0-K6Xi0z"
      },
      "outputs": [],
      "source": [
        "!pip install -qU bitsandbytes triton\n",
        "import bitsandbytes, triton"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python loadLLM.py\n",
        "from loadLLM import loadLLM\n",
        "!python nlp_sciLit.py\n",
        "from nlp_sciLit import nlp_sciLit"
      ],
      "metadata": {
        "id": "SzxYrlYBsnFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoHWpPUgQ0Fz"
      },
      "outputs": [],
      "source": [
        "model, tokenizer = loadLLM(llm=\"Uni-SMART/SciLitLLM1.5-14B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VFq8KcjQsOs"
      },
      "outputs": [],
      "source": [
        "os.chdir(scrapyDir)\n",
        "import re\n",
        "for file in txt_files:\n",
        "  print(file)\n",
        "  text=read_content(file)\n",
        "  response = nlp_sciLit(text, model, tokenizer)\n",
        "  output_filename=re.sub(r'[\\w]+/', '', file)\n",
        "  SciLit_file=os.path.join('SciLit', output_filename)\n",
        "  with open( SciLit_file, \"a\") as filehandler:\n",
        "    filehandler.write(\"\\n\\nMain text summary\\n\\n\")\n",
        "    filehandler.write(response)\n",
        "    filehandler.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzRahHXHCVES"
      },
      "source": [
        "Move everything to new 'RESULTS' folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGtKmg7nCOLG"
      },
      "outputs": [],
      "source": [
        "os.mkdir(os.path.join(paperParserDir,'RESULTS'))\n",
        "os.chdir(paperParserDir)\n",
        "!mv -i \"${PWD}/scraping_rev9/SciLit\" \"${PWD}/RESULTS\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv -i \"${PWD}/scraping_rev9/abstracts\" \"${PWD}/RESULTS\"\n",
        "!mv -i \"${PWD}/scraping_rev9/articlesSummaries\" \"${PWD}/RESULTS\"\n",
        "!mv -i \"${PWD}/scraping_rev9/mainTexts\" \"${PWD}/RESULTS\""
      ],
      "metadata": {
        "id": "w7q_zotwaEPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWlXvmbHZDbI"
      },
      "source": [
        "#***PART 2: TEXT GENERATION BY ARTIFICIAL INTELLIGENCE ALGORITHMS***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMc8fok48PJe"
      },
      "source": [
        "Merge the summaries to create the input for algorithm of generative artificial intelligence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLNLEUlpp3QT"
      },
      "outputs": [],
      "source": [
        "os.chdir(LLMsDir)\n",
        "\n",
        "!python connectOpenAI.py\n",
        "from connectOpenAI import connectOpenAI\n",
        "!python generateFramework.py\n",
        "from generateFramework import generateFramework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YeFGk8knwHW"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"Organization_ID\"] = userdata.get('Organization_ID')\n",
        "os.environ[\"PROJECT_ID\"] = userdata.get('PROJECT_ID')\n",
        "client = connectOpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], organization = os.environ[\"Organization_ID\"], project= os.environ[\"PROJECT_ID\"] )\n",
        "print(\"openAI client:\")\n",
        "print(client)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultsDir=os.path.join(paperParserDir,'RESULTS')"
      ],
      "metadata": {
        "id": "ydU3TEr2s2iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQh_rwKnZYLe"
      },
      "outputs": [],
      "source": [
        "#generate inputs for AI application\n",
        "suffixes=(\"_direct\",\"_reverse\")\n",
        "AI_inputs= [AI_input_direct, AI_input_reverse]= mergeSummaries(outputDir=resultsDir, inputDir= os.path.join(resultsDir,'SciLit'), suffixes= suffixes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuVfj7Sb85c4"
      },
      "source": [
        "**Generation of drafts' frameworks with prompt engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCX6tV3D0rKw"
      },
      "source": [
        "Prompt engineering is the process of structuring or crafting an instruction in order to produce the best possible output from a generative artificial intelligence (AI) model.\n",
        "\n",
        "\n",
        "Genkina, Dina (March 6, 2024). \"AI Prompt Engineering is Dead: Long live AI prompt engineering\". IEEE Spectrum. Retrieved January 18, 2025."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw6pZUXWXxwG"
      },
      "outputs": [],
      "source": [
        "name=\"framework\"\n",
        "frameworks=[generateFramework(client=client, AI_input=AI_inputs[0],resultsDir=resultsDir, output_filename=name+suffixes[0]+\".txt\"),\n",
        "        generateFramework(client=client, AI_input=AI_inputs[1], resultsDir=resultsDir, output_filename=name+suffixes[1]+\".txt\")\n",
        "        ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uytpVfUIY8Fl"
      },
      "source": [
        "##***GENERATE DRAFTS BY REPL AND RAG***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg0IrFUwd7kK"
      },
      "source": [
        "REPL is an acronym for Read, Evaluate, Print, and Loop. Developers use REPL Python to communicate with the Python Interpreter.\n",
        "\n",
        "Ellis, Kevin, et al. “Write, Execute, Assess: Program Synthesis with a REPL.” ArXiv.org, 2019, arxiv.org/abs/1906.04604."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtXXKn3reD5U"
      },
      "source": [
        "RAG (Retrieval-Augmented Generation) is the process of optimizing the output of a large language model, so it references an authoritative knowledge base outside of its training data sources before generating a response.\n",
        "\n",
        "Lewis, Patrick, et al. “Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.” ArXiv.org, 12 Apr. 2021, arxiv.org/abs/2005.11401."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch48TUlsA5wl"
      },
      "source": [
        "Install langchain modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7d8bbo89z_t"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_huggingface\n",
        "!pip install langchain_openai\n",
        "!pip install langchain_community\n",
        "!pip install langchain_experimental\n",
        "!pip install -qU langchain-community faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diIXYr6yi3kV"
      },
      "outputs": [],
      "source": [
        "#os.chdir(LLMsDir)\n",
        "!python selectTools.py\n",
        "from selectTools import (selectModel, selectREPLagent)\n",
        "!python manageParagraphs.py\n",
        "from manageParagraphs import (identifyParagraphs, retrieveParagraphContent)\n",
        "!python buildRetriever.py\n",
        "from buildRetriever import (getRetriever, format_docs, get_text_chunks_from_str)\n",
        "!python generateExtensions.py\n",
        "from generateExtensions import (generateAbstract, extendParagraphs, addReferences)\n",
        "!python elongateFrameworks.py\n",
        "from elongateFrameworks import elongateFrameworks\n",
        "!python mergeDrafts.py\n",
        "from mergeDrafts import (merge2Drafts, mergingOp)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "!pip install hf-xet"
      ],
      "metadata": {
        "id": "1fuYe6CJ9Xih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extend the paragraphs composing the frameworks"
      ],
      "metadata": {
        "id": "47wPFuT1E6wF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FlqpG_ItU_l"
      },
      "outputs": [],
      "source": [
        "drafts= elongateFrameworks(frameworks, resultsDir, AI_inputs, suffixes, api_key=os.environ[\"OPENAI_API_KEY\"], organization = os.environ[\"Organization_ID\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merge two drafts"
      ],
      "metadata": {
        "id": "K9SmK3xaCYfT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sn3tyg73EY1E"
      },
      "outputs": [],
      "source": [
        "drafts_merged= merge2Drafts(drafts,resultsDir, api_key=os.environ[\"OPENAI_API_KEY\"], organization = os.environ[\"Organization_ID\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4HB6DVi35mD"
      },
      "outputs": [],
      "source": [
        "name=\"drafts_merged\"\n",
        "printPDF(name,drafts_merged, resultsDir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ipQTAL2XTsx"
      },
      "source": [
        "#***PART 3: HUMANIZE AI-GENERATED TEXT***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsXy1-f0XPGq"
      },
      "outputs": [],
      "source": [
        "drafts_merged=read_content(os.path.join(paperParserDir,'RESULTS',\"drafts_merged.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lr70A4VFXjIJ"
      },
      "outputs": [],
      "source": [
        "examples=read_content(os.path.join(paperParserDir,\"examples.txt\"))\n",
        "system_content=read_content(os.path.join(paperParserDir,\"system_content.txt\"))\n",
        "user_instructions=read_content(os.path.join(paperParserDir,\"user_instructions.txt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-polDoiM1e6X"
      },
      "outputs": [],
      "source": [
        "os.chdir(LLMsDir)\n",
        "!python humanizeTexts.py\n",
        "from humanizeTexts import (humanize, humanizeOp, callHumanizingApp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5osN0GPb9tqF"
      },
      "outputs": [],
      "source": [
        "email= None\n",
        "pwd= None\n",
        "humanizedDraft, paragraphsDir =humanize(examples, drafts_merged, system_content, user_instructions, resultsDir, api_key=os.environ[\"OPENAI_API_KEY\"], organization = os.environ[\"Organization_ID\"],email=email, pwd=pwd)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "humanizedDraft=read_content(os.path.join(paperParserDir,'RESULTS',\"humanized.txt\"))"
      ],
      "metadata": {
        "id": "IqZ-fohavlz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlXZs-E3HhGB"
      },
      "outputs": [],
      "source": [
        "if email is None or pwd is None:\n",
        "\tname=\"humanized\"\n",
        "else:\n",
        "\tname=\"humanized_antiDetector\"\n",
        "printPDF(name,humanizedDraft, resultsDir)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}